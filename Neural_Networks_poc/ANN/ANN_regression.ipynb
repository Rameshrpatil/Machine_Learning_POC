{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('D:/Python programming/Machine learning/POC/Neural_Networks_poc/Datasets/Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='Serial No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "Y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 7)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xte,Ytr,Yte=train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_scale=scale.fit_transform(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte_scale=scale.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RameshPatil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.4474 - val_loss: 0.4605\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4095 - val_loss: 0.4213\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3528 - val_loss: 0.3827\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3358 - val_loss: 0.3420\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2994 - val_loss: 0.3000\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2559 - val_loss: 0.2567\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2169 - val_loss: 0.2091\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1810 - val_loss: 0.1579\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1299 - val_loss: 0.1101\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0926 - val_loss: 0.0724\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0592 - val_loss: 0.0488\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0452 - val_loss: 0.0368\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0386 - val_loss: 0.0322\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0365 - val_loss: 0.0303\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0340 - val_loss: 0.0291\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0334 - val_loss: 0.0280\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0294 - val_loss: 0.0270\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0301 - val_loss: 0.0260\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0277 - val_loss: 0.0250\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0261 - val_loss: 0.0240\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0267 - val_loss: 0.0231\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0222\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0214\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0207\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0201\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0193\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0187\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0181\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0176\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0170\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0182 - val_loss: 0.0164\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0160\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0170 - val_loss: 0.0156\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0167 - val_loss: 0.0151\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0161 - val_loss: 0.0147\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0151 - val_loss: 0.0142\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0160 - val_loss: 0.0138\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - val_loss: 0.0135\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.0123\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0087\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0059\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(Xtr_scale,Ytr,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001905669D800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001905669D800> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(Xte_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605299495777734"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Yte,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19058fb8290>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

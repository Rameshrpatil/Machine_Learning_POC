{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RameshPatil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization is used to convert sentences to words \n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of word\n",
    "\n",
    "paragragh ='''NLP combines the power of computational linguistics together with machine learning algorithms and deep learning. Computational linguistics is a discipline of linguistics that uses data science to analyze language and speech. It includes two main types of analysis: syntactical analysis and semantical analysis. Syntactical analysis determines the meaning of a word, phrase or sentence by parsing the syntax of the words and applying preprogrammed rules of grammar. Semantical analysis uses the syntactic output to draw meaning from the words and interpret their meaning within the sentence structure.The parsing of words can take one of two forms. Dependency parsing looks at the relationships between words, such as identifying nouns and verbs, while constituency parsing then builds a parse tree (or syntax tree): a rooted and ordered representation of the syntactic structure of the sentence or string of words. The resulting parse trees underly the functions of language translators and speech recognition. Ideally, this analysis makes the output—either text or speech—understandable to both NLP models and people.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragragh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP combines the power of computational linguistics together with machine learning algorithms and deep learning.', 'Computational linguistics is a discipline of linguistics that uses data science to analyze language and speech.', 'It includes two main types of analysis: syntactical analysis and semantical analysis.', 'Syntactical analysis determines the meaning of a word, phrase or sentence by parsing the syntax of the words and applying preprogrammed rules of grammar.', 'Semantical analysis uses the syntactic output to draw meaning from the words and interpret their meaning within the sentence structure.The parsing of words can take one of two forms.', 'Dependency parsing looks at the relationships between words, such as identifying nouns and verbs, while constituency parsing then builds a parse tree (or syntax tree): a rooted and ordered representation of the syntactic structure of the sentence or string of words.', 'The resulting parse trees underly the functions of language translators and speech recognition.', 'Ideally, this analysis makes the output—either text or speech—understandable to both NLP models and people.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"drink'\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"drink's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RameshPatil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drinking'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('drinking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_stem =stemmer.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histori\n"
     ]
    }
   ],
   "source": [
    "print(hist_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(hist_stem) # lemmatizer does not change the the stemed word from the stemmer instead it is used as option for stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "corpus =[]\n",
    "for i in range(len(sentences)):\n",
    "    review =re.sub(r'[^a-zA-Z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlp combines the power of computational linguistics together with machine learning algorithms and deep learning ',\n",
       " 'computational linguistics is a discipline of linguistics that uses data science to analyze language and speech ',\n",
       " 'it includes two main types of analysis  syntactical analysis and semantical analysis ',\n",
       " 'syntactical analysis determines the meaning of a word  phrase or sentence by parsing the syntax of the words and applying preprogrammed rules of grammar ',\n",
       " 'semantical analysis uses the syntactic output to draw meaning from the words and interpret their meaning within the sentence structure the parsing of words can take one of two forms ',\n",
       " 'dependency parsing looks at the relationships between words  such as identifying nouns and verbs  while constituency parsing then builds a parse tree  or syntax tree   a rooted and ordered representation of the syntactic structure of the sentence or string of words ',\n",
       " 'the resulting parse trees underly the functions of language translators and speech recognition ',\n",
       " 'ideally  this analysis makes the output either text or speech understandable to both nlp models and people ']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RameshPatil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp\n",
      "combin\n",
      "power\n",
      "comput\n",
      "linguist\n",
      "togeth\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      "deep\n",
      "learn\n",
      "comput\n",
      "linguist\n",
      "disciplin\n",
      "linguist\n",
      "use\n",
      "data\n",
      "scienc\n",
      "analyz\n",
      "languag\n",
      "speech\n",
      "includ\n",
      "two\n",
      "main\n",
      "type\n",
      "analysi\n",
      "syntact\n",
      "analysi\n",
      "semant\n",
      "analysi\n",
      "syntact\n",
      "analysi\n",
      "determin\n",
      "mean\n",
      "word\n",
      "phrase\n",
      "sentenc\n",
      "pars\n",
      "syntax\n",
      "word\n",
      "appli\n",
      "preprogram\n",
      "rule\n",
      "grammar\n",
      "semant\n",
      "analysi\n",
      "use\n",
      "syntact\n",
      "output\n",
      "draw\n",
      "mean\n",
      "word\n",
      "interpret\n",
      "mean\n",
      "within\n",
      "sentenc\n",
      "structur\n",
      "pars\n",
      "word\n",
      "take\n",
      "one\n",
      "two\n",
      "form\n",
      "depend\n",
      "pars\n",
      "look\n",
      "relationship\n",
      "word\n",
      "identifi\n",
      "noun\n",
      "verb\n",
      "constitu\n",
      "pars\n",
      "build\n",
      "pars\n",
      "tree\n",
      "syntax\n",
      "tree\n",
      "root\n",
      "order\n",
      "represent\n",
      "syntact\n",
      "structur\n",
      "sentenc\n",
      "string\n",
      "word\n",
      "result\n",
      "pars\n",
      "tree\n",
      "underli\n",
      "function\n",
      "languag\n",
      "translat\n",
      "speech\n",
      "recognit\n",
      "ideal\n",
      "analysi\n",
      "make\n",
      "output\n",
      "either\n",
      "text\n",
      "speech\n",
      "understand\n",
      "nlp\n",
      "model\n",
      "peopl\n"
     ]
    }
   ],
   "source": [
    "##stemming\n",
    "for i in corpus:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp\n",
      "combine\n",
      "power\n",
      "computational\n",
      "linguistics\n",
      "together\n",
      "machine\n",
      "learning\n",
      "algorithm\n",
      "deep\n",
      "learning\n",
      "computational\n",
      "linguistics\n",
      "discipline\n",
      "linguistics\n",
      "us\n",
      "data\n",
      "science\n",
      "analyze\n",
      "language\n",
      "speech\n",
      "includes\n",
      "two\n",
      "main\n",
      "type\n",
      "analysis\n",
      "syntactical\n",
      "analysis\n",
      "semantical\n",
      "analysis\n",
      "syntactical\n",
      "analysis\n",
      "determines\n",
      "meaning\n",
      "word\n",
      "phrase\n",
      "sentence\n",
      "parsing\n",
      "syntax\n",
      "word\n",
      "applying\n",
      "preprogrammed\n",
      "rule\n",
      "grammar\n",
      "semantical\n",
      "analysis\n",
      "us\n",
      "syntactic\n",
      "output\n",
      "draw\n",
      "meaning\n",
      "word\n",
      "interpret\n",
      "meaning\n",
      "within\n",
      "sentence\n",
      "structure\n",
      "parsing\n",
      "word\n",
      "take\n",
      "one\n",
      "two\n",
      "form\n",
      "dependency\n",
      "parsing\n",
      "look\n",
      "relationship\n",
      "word\n",
      "identifying\n",
      "noun\n",
      "verb\n",
      "constituency\n",
      "parsing\n",
      "build\n",
      "parse\n",
      "tree\n",
      "syntax\n",
      "tree\n",
      "rooted\n",
      "ordered\n",
      "representation\n",
      "syntactic\n",
      "structure\n",
      "sentence\n",
      "string\n",
      "word\n",
      "resulting\n",
      "parse\n",
      "tree\n",
      "underly\n",
      "function\n",
      "language\n",
      "translator\n",
      "speech\n",
      "recognition\n",
      "ideally\n",
      "analysis\n",
      "make\n",
      "output\n",
      "either\n",
      "text\n",
      "speech\n",
      "understandable\n",
      "nlp\n",
      "model\n",
      "people\n"
     ]
    }
   ],
   "source": [
    "##lemmatization\n",
    "for i in corpus:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying Stopwords, lemmatization\n",
    "import re \n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vetorization \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 31,\n",
       " 'combine': 5,\n",
       " 'power': 40,\n",
       " 'computational': 6,\n",
       " 'linguistics': 24,\n",
       " 'together': 59,\n",
       " 'machine': 26,\n",
       " 'learning': 23,\n",
       " 'algorithm': 0,\n",
       " 'deep': 9,\n",
       " 'discipline': 12,\n",
       " 'us': 66,\n",
       " 'data': 8,\n",
       " 'science': 48,\n",
       " 'analyze': 2,\n",
       " 'language': 22,\n",
       " 'speech': 51,\n",
       " 'includes': 20,\n",
       " 'two': 62,\n",
       " 'main': 27,\n",
       " 'type': 63,\n",
       " 'analysis': 1,\n",
       " 'syntactical': 55,\n",
       " 'semantical': 49,\n",
       " 'determines': 11,\n",
       " 'meaning': 29,\n",
       " 'word': 69,\n",
       " 'phrase': 39,\n",
       " 'sentence': 50,\n",
       " 'parsing': 37,\n",
       " 'syntax': 56,\n",
       " 'applying': 3,\n",
       " 'preprogrammed': 41,\n",
       " 'rule': 47,\n",
       " 'grammar': 17,\n",
       " 'syntactic': 54,\n",
       " 'output': 35,\n",
       " 'draw': 13,\n",
       " 'interpret': 21,\n",
       " 'within': 68,\n",
       " 'structure': 53,\n",
       " 'take': 57,\n",
       " 'one': 33,\n",
       " 'form': 15,\n",
       " 'dependency': 10,\n",
       " 'look': 25,\n",
       " 'relationship': 43,\n",
       " 'identifying': 19,\n",
       " 'noun': 32,\n",
       " 'verb': 67,\n",
       " 'constituency': 7,\n",
       " 'build': 4,\n",
       " 'parse': 36,\n",
       " 'tree': 61,\n",
       " 'rooted': 46,\n",
       " 'ordered': 34,\n",
       " 'representation': 44,\n",
       " 'string': 52,\n",
       " 'resulting': 45,\n",
       " 'underly': 64,\n",
       " 'function': 16,\n",
       " 'translator': 60,\n",
       " 'recognition': 42,\n",
       " 'ideally': 18,\n",
       " 'make': 28,\n",
       " 'either': 14,\n",
       " 'text': 58,\n",
       " 'understandable': 65,\n",
       " 'model': 30,\n",
       " 'people': 38}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp combine power computational linguistics together machine learning algorithm deep learning'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngrams ---> bigrams\n",
    "cv2= CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp combine': 37,\n",
       " 'combine power': 9,\n",
       " 'power computational': 50,\n",
       " 'computational linguistics': 10,\n",
       " 'linguistics together': 28,\n",
       " 'together machine': 74,\n",
       " 'machine learning': 31,\n",
       " 'learning algorithm': 26,\n",
       " 'algorithm deep': 0,\n",
       " 'deep learning': 13,\n",
       " 'linguistics discipline': 27,\n",
       " 'discipline linguistics': 16,\n",
       " 'linguistics us': 29,\n",
       " 'us data': 84,\n",
       " 'data science': 12,\n",
       " 'science analyze': 57,\n",
       " 'analyze language': 6,\n",
       " 'language speech': 24,\n",
       " 'includes two': 22,\n",
       " 'two main': 80,\n",
       " 'main type': 32,\n",
       " 'type analysis': 81,\n",
       " 'analysis syntactical': 4,\n",
       " 'syntactical analysis': 69,\n",
       " 'analysis semantical': 3,\n",
       " 'semantical analysis': 58,\n",
       " 'analysis determines': 1,\n",
       " 'determines meaning': 15,\n",
       " 'meaning word': 35,\n",
       " 'word phrase': 91,\n",
       " 'phrase sentence': 49,\n",
       " 'sentence parsing': 59,\n",
       " 'parsing syntax': 47,\n",
       " 'syntax word': 71,\n",
       " 'word applying': 88,\n",
       " 'applying preprogrammed': 7,\n",
       " 'preprogrammed rule': 51,\n",
       " 'rule grammar': 56,\n",
       " 'analysis us': 5,\n",
       " 'us syntactic': 85,\n",
       " 'syntactic output': 67,\n",
       " 'output draw': 42,\n",
       " 'draw meaning': 17,\n",
       " 'word interpret': 90,\n",
       " 'interpret meaning': 23,\n",
       " 'meaning within': 34,\n",
       " 'within sentence': 87,\n",
       " 'sentence structure': 61,\n",
       " 'structure parsing': 65,\n",
       " 'parsing word': 48,\n",
       " 'word take': 92,\n",
       " 'take one': 72,\n",
       " 'one two': 40,\n",
       " 'two form': 79,\n",
       " 'dependency parsing': 14,\n",
       " 'parsing look': 46,\n",
       " 'look relationship': 30,\n",
       " 'relationship word': 52,\n",
       " 'word identifying': 89,\n",
       " 'identifying noun': 21,\n",
       " 'noun verb': 39,\n",
       " 'verb constituency': 86,\n",
       " 'constituency parsing': 11,\n",
       " 'parsing build': 45,\n",
       " 'build parse': 8,\n",
       " 'parse tree': 44,\n",
       " 'tree syntax': 77,\n",
       " 'syntax tree': 70,\n",
       " 'tree rooted': 76,\n",
       " 'rooted ordered': 55,\n",
       " 'ordered representation': 41,\n",
       " 'representation syntactic': 53,\n",
       " 'syntactic structure': 68,\n",
       " 'structure sentence': 66,\n",
       " 'sentence string': 60,\n",
       " 'string word': 64,\n",
       " 'resulting parse': 54,\n",
       " 'tree underly': 78,\n",
       " 'underly function': 82,\n",
       " 'function language': 19,\n",
       " 'language translator': 25,\n",
       " 'translator speech': 75,\n",
       " 'speech recognition': 62,\n",
       " 'ideally analysis': 20,\n",
       " 'analysis make': 2,\n",
       " 'make output': 33,\n",
       " 'output either': 43,\n",
       " 'either text': 18,\n",
       " 'text speech': 73,\n",
       " 'speech understandable': 63,\n",
       " 'understandable nlp': 83,\n",
       " 'nlp model': 38,\n",
       " 'model people': 36}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 =cv2.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 93)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngrams ---> trigrams\n",
    "cv3 =CountVectorizer(ngram_range=(3,3))\n",
    "X2=cv3.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp combine power': 36,\n",
       " 'combine power computational': 9,\n",
       " 'power computational linguistics': 50,\n",
       " 'computational linguistics together': 11,\n",
       " 'linguistics together machine': 27,\n",
       " 'together machine learning': 72,\n",
       " 'machine learning algorithm': 30,\n",
       " 'learning algorithm deep': 25,\n",
       " 'algorithm deep learning': 0,\n",
       " 'computational linguistics discipline': 10,\n",
       " 'linguistics discipline linguistics': 26,\n",
       " 'discipline linguistics us': 16,\n",
       " 'linguistics us data': 28,\n",
       " 'us data science': 81,\n",
       " 'data science analyze': 13,\n",
       " 'science analyze language': 56,\n",
       " 'analyze language speech': 6,\n",
       " 'includes two main': 22,\n",
       " 'two main type': 77,\n",
       " 'main type analysis': 31,\n",
       " 'type analysis syntactical': 78,\n",
       " 'analysis syntactical analysis': 4,\n",
       " 'syntactical analysis semantical': 67,\n",
       " 'analysis semantical analysis': 3,\n",
       " 'syntactical analysis determines': 66,\n",
       " 'analysis determines meaning': 1,\n",
       " 'determines meaning word': 15,\n",
       " 'meaning word phrase': 35,\n",
       " 'word phrase sentence': 88,\n",
       " 'phrase sentence parsing': 49,\n",
       " 'sentence parsing syntax': 58,\n",
       " 'parsing syntax word': 47,\n",
       " 'syntax word applying': 69,\n",
       " 'word applying preprogrammed': 85,\n",
       " 'applying preprogrammed rule': 7,\n",
       " 'preprogrammed rule grammar': 51,\n",
       " 'semantical analysis us': 57,\n",
       " 'analysis us syntactic': 5,\n",
       " 'us syntactic output': 82,\n",
       " 'syntactic output draw': 64,\n",
       " 'output draw meaning': 41,\n",
       " 'draw meaning word': 17,\n",
       " 'meaning word interpret': 34,\n",
       " 'word interpret meaning': 87,\n",
       " 'interpret meaning within': 23,\n",
       " 'meaning within sentence': 33,\n",
       " 'within sentence structure': 84,\n",
       " 'sentence structure parsing': 60,\n",
       " 'structure parsing word': 62,\n",
       " 'parsing word take': 48,\n",
       " 'word take one': 89,\n",
       " 'take one two': 70,\n",
       " 'one two form': 39,\n",
       " 'dependency parsing look': 14,\n",
       " 'parsing look relationship': 46,\n",
       " 'look relationship word': 29,\n",
       " 'relationship word identifying': 52,\n",
       " 'word identifying noun': 86,\n",
       " 'identifying noun verb': 21,\n",
       " 'noun verb constituency': 38,\n",
       " 'verb constituency parsing': 83,\n",
       " 'constituency parsing build': 12,\n",
       " 'parsing build parse': 45,\n",
       " 'build parse tree': 8,\n",
       " 'parse tree syntax': 43,\n",
       " 'tree syntax tree': 75,\n",
       " 'syntax tree rooted': 68,\n",
       " 'tree rooted ordered': 74,\n",
       " 'rooted ordered representation': 55,\n",
       " 'ordered representation syntactic': 40,\n",
       " 'representation syntactic structure': 53,\n",
       " 'syntactic structure sentence': 65,\n",
       " 'structure sentence string': 63,\n",
       " 'sentence string word': 59,\n",
       " 'resulting parse tree': 54,\n",
       " 'parse tree underly': 44,\n",
       " 'tree underly function': 76,\n",
       " 'underly function language': 79,\n",
       " 'function language translator': 19,\n",
       " 'language translator speech': 24,\n",
       " 'translator speech recognition': 73,\n",
       " 'ideally analysis make': 20,\n",
       " 'analysis make output': 2,\n",
       " 'make output either': 32,\n",
       " 'output either text': 42,\n",
       " 'either text speech': 18,\n",
       " 'text speech understandable': 71,\n",
       " 'speech understandable nlp': 61,\n",
       " 'understandable nlp model': 80,\n",
       " 'nlp model people': 37}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 90)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngrams\n",
    "cv4=CountVectorizer(ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=cv4.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 137,\n",
       " 'combine': 29,\n",
       " 'power': 185,\n",
       " 'computational': 33,\n",
       " 'linguistics': 100,\n",
       " 'together': 270,\n",
       " 'machine': 114,\n",
       " 'learning': 96,\n",
       " 'algorithm': 0,\n",
       " 'deep': 47,\n",
       " 'nlp combine': 138,\n",
       " 'combine power': 30,\n",
       " 'power computational': 186,\n",
       " 'computational linguistics': 34,\n",
       " 'linguistics together': 104,\n",
       " 'together machine': 271,\n",
       " 'machine learning': 115,\n",
       " 'learning algorithm': 97,\n",
       " 'algorithm deep': 1,\n",
       " 'deep learning': 48,\n",
       " 'nlp combine power': 139,\n",
       " 'combine power computational': 31,\n",
       " 'power computational linguistics': 187,\n",
       " 'computational linguistics together': 37,\n",
       " 'linguistics together machine': 105,\n",
       " 'together machine learning': 272,\n",
       " 'machine learning algorithm': 116,\n",
       " 'learning algorithm deep': 98,\n",
       " 'algorithm deep learning': 2,\n",
       " 'nlp combine power computational': 140,\n",
       " 'combine power computational linguistics': 32,\n",
       " 'power computational linguistics together': 188,\n",
       " 'computational linguistics together machine': 38,\n",
       " 'linguistics together machine learning': 106,\n",
       " 'together machine learning algorithm': 273,\n",
       " 'machine learning algorithm deep': 117,\n",
       " 'learning algorithm deep learning': 99,\n",
       " 'discipline': 57,\n",
       " 'us': 304,\n",
       " 'data': 43,\n",
       " 'science': 211,\n",
       " 'analyze': 18,\n",
       " 'language': 91,\n",
       " 'speech': 228,\n",
       " 'linguistics discipline': 101,\n",
       " 'discipline linguistics': 58,\n",
       " 'linguistics us': 107,\n",
       " 'us data': 305,\n",
       " 'data science': 44,\n",
       " 'science analyze': 212,\n",
       " 'analyze language': 19,\n",
       " 'language speech': 92,\n",
       " 'computational linguistics discipline': 35,\n",
       " 'linguistics discipline linguistics': 102,\n",
       " 'discipline linguistics us': 59,\n",
       " 'linguistics us data': 108,\n",
       " 'us data science': 306,\n",
       " 'data science analyze': 45,\n",
       " 'science analyze language': 213,\n",
       " 'analyze language speech': 20,\n",
       " 'computational linguistics discipline linguistics': 36,\n",
       " 'linguistics discipline linguistics us': 103,\n",
       " 'discipline linguistics us data': 60,\n",
       " 'linguistics us data science': 109,\n",
       " 'us data science analyze': 307,\n",
       " 'data science analyze language': 46,\n",
       " 'science analyze language speech': 214,\n",
       " 'includes': 83,\n",
       " 'two': 287,\n",
       " 'main': 118,\n",
       " 'type': 292,\n",
       " 'analysis': 3,\n",
       " 'syntactical': 249,\n",
       " 'semantical': 215,\n",
       " 'includes two': 84,\n",
       " 'two main': 289,\n",
       " 'main type': 119,\n",
       " 'type analysis': 293,\n",
       " 'analysis syntactical': 12,\n",
       " 'syntactical analysis': 250,\n",
       " 'analysis semantical': 10,\n",
       " 'semantical analysis': 216,\n",
       " 'includes two main': 85,\n",
       " 'two main type': 290,\n",
       " 'main type analysis': 120,\n",
       " 'type analysis syntactical': 294,\n",
       " 'analysis syntactical analysis': 13,\n",
       " 'syntactical analysis semantical': 253,\n",
       " 'analysis semantical analysis': 11,\n",
       " 'includes two main type': 86,\n",
       " 'two main type analysis': 291,\n",
       " 'main type analysis syntactical': 121,\n",
       " 'type analysis syntactical analysis': 295,\n",
       " 'analysis syntactical analysis semantical': 14,\n",
       " 'syntactical analysis semantical analysis': 254,\n",
       " 'determines': 53,\n",
       " 'meaning': 126,\n",
       " 'word': 319,\n",
       " 'phrase': 181,\n",
       " 'sentence': 219,\n",
       " 'parsing': 167,\n",
       " 'syntax': 255,\n",
       " 'applying': 21,\n",
       " 'preprogrammed': 189,\n",
       " 'rule': 209,\n",
       " 'grammar': 74,\n",
       " 'analysis determines': 4,\n",
       " 'determines meaning': 54,\n",
       " 'meaning word': 130,\n",
       " 'word phrase': 329,\n",
       " 'phrase sentence': 182,\n",
       " 'sentence parsing': 220,\n",
       " 'parsing syntax': 174,\n",
       " 'syntax word': 259,\n",
       " 'word applying': 320,\n",
       " 'applying preprogrammed': 22,\n",
       " 'preprogrammed rule': 190,\n",
       " 'rule grammar': 210,\n",
       " 'syntactical analysis determines': 251,\n",
       " 'analysis determines meaning': 5,\n",
       " 'determines meaning word': 55,\n",
       " 'meaning word phrase': 133,\n",
       " 'word phrase sentence': 330,\n",
       " 'phrase sentence parsing': 183,\n",
       " 'sentence parsing syntax': 221,\n",
       " 'parsing syntax word': 175,\n",
       " 'syntax word applying': 260,\n",
       " 'word applying preprogrammed': 321,\n",
       " 'applying preprogrammed rule': 23,\n",
       " 'preprogrammed rule grammar': 191,\n",
       " 'syntactical analysis determines meaning': 252,\n",
       " 'analysis determines meaning word': 6,\n",
       " 'determines meaning word phrase': 56,\n",
       " 'meaning word phrase sentence': 134,\n",
       " 'word phrase sentence parsing': 331,\n",
       " 'phrase sentence parsing syntax': 184,\n",
       " 'sentence parsing syntax word': 222,\n",
       " 'parsing syntax word applying': 176,\n",
       " 'syntax word applying preprogrammed': 261,\n",
       " 'word applying preprogrammed rule': 322,\n",
       " 'applying preprogrammed rule grammar': 24,\n",
       " 'syntactic': 242,\n",
       " 'output': 154,\n",
       " 'draw': 61,\n",
       " 'interpret': 87,\n",
       " 'within': 315,\n",
       " 'structure': 235,\n",
       " 'take': 262,\n",
       " 'one': 147,\n",
       " 'form': 69,\n",
       " 'analysis us': 15,\n",
       " 'us syntactic': 308,\n",
       " 'syntactic output': 243,\n",
       " 'output draw': 155,\n",
       " 'draw meaning': 62,\n",
       " 'word interpret': 326,\n",
       " 'interpret meaning': 88,\n",
       " 'meaning within': 127,\n",
       " 'within sentence': 316,\n",
       " 'sentence structure': 225,\n",
       " 'structure parsing': 236,\n",
       " 'parsing word': 177,\n",
       " 'word take': 332,\n",
       " 'take one': 263,\n",
       " 'one two': 148,\n",
       " 'two form': 288,\n",
       " 'semantical analysis us': 217,\n",
       " 'analysis us syntactic': 16,\n",
       " 'us syntactic output': 309,\n",
       " 'syntactic output draw': 244,\n",
       " 'output draw meaning': 156,\n",
       " 'draw meaning word': 63,\n",
       " 'meaning word interpret': 131,\n",
       " 'word interpret meaning': 327,\n",
       " 'interpret meaning within': 89,\n",
       " 'meaning within sentence': 128,\n",
       " 'within sentence structure': 317,\n",
       " 'sentence structure parsing': 226,\n",
       " 'structure parsing word': 237,\n",
       " 'parsing word take': 178,\n",
       " 'word take one': 333,\n",
       " 'take one two': 264,\n",
       " 'one two form': 149,\n",
       " 'semantical analysis us syntactic': 218,\n",
       " 'analysis us syntactic output': 17,\n",
       " 'us syntactic output draw': 310,\n",
       " 'syntactic output draw meaning': 245,\n",
       " 'output draw meaning word': 157,\n",
       " 'draw meaning word interpret': 64,\n",
       " 'meaning word interpret meaning': 132,\n",
       " 'word interpret meaning within': 328,\n",
       " 'interpret meaning within sentence': 90,\n",
       " 'meaning within sentence structure': 129,\n",
       " 'within sentence structure parsing': 318,\n",
       " 'sentence structure parsing word': 227,\n",
       " 'structure parsing word take': 238,\n",
       " 'parsing word take one': 179,\n",
       " 'word take one two': 334,\n",
       " 'take one two form': 265,\n",
       " 'dependency': 49,\n",
       " 'look': 110,\n",
       " 'relationship': 193,\n",
       " 'identifying': 79,\n",
       " 'noun': 143,\n",
       " 'verb': 311,\n",
       " 'constituency': 39,\n",
       " 'build': 25,\n",
       " 'parse': 161,\n",
       " 'tree': 277,\n",
       " 'rooted': 205,\n",
       " 'ordered': 150,\n",
       " 'representation': 197,\n",
       " 'string': 233,\n",
       " 'dependency parsing': 50,\n",
       " 'parsing look': 171,\n",
       " 'look relationship': 111,\n",
       " 'relationship word': 194,\n",
       " 'word identifying': 323,\n",
       " 'identifying noun': 80,\n",
       " 'noun verb': 144,\n",
       " 'verb constituency': 312,\n",
       " 'constituency parsing': 40,\n",
       " 'parsing build': 168,\n",
       " 'build parse': 26,\n",
       " 'parse tree': 162,\n",
       " 'tree syntax': 281,\n",
       " 'syntax tree': 256,\n",
       " 'tree rooted': 278,\n",
       " 'rooted ordered': 206,\n",
       " 'ordered representation': 151,\n",
       " 'representation syntactic': 198,\n",
       " 'syntactic structure': 246,\n",
       " 'structure sentence': 239,\n",
       " 'sentence string': 223,\n",
       " 'string word': 234,\n",
       " 'dependency parsing look': 51,\n",
       " 'parsing look relationship': 172,\n",
       " 'look relationship word': 112,\n",
       " 'relationship word identifying': 195,\n",
       " 'word identifying noun': 324,\n",
       " 'identifying noun verb': 81,\n",
       " 'noun verb constituency': 145,\n",
       " 'verb constituency parsing': 313,\n",
       " 'constituency parsing build': 41,\n",
       " 'parsing build parse': 169,\n",
       " 'build parse tree': 27,\n",
       " 'parse tree syntax': 163,\n",
       " 'tree syntax tree': 282,\n",
       " 'syntax tree rooted': 257,\n",
       " 'tree rooted ordered': 279,\n",
       " 'rooted ordered representation': 207,\n",
       " 'ordered representation syntactic': 152,\n",
       " 'representation syntactic structure': 199,\n",
       " 'syntactic structure sentence': 247,\n",
       " 'structure sentence string': 240,\n",
       " 'sentence string word': 224,\n",
       " 'dependency parsing look relationship': 52,\n",
       " 'parsing look relationship word': 173,\n",
       " 'look relationship word identifying': 113,\n",
       " 'relationship word identifying noun': 196,\n",
       " 'word identifying noun verb': 325,\n",
       " 'identifying noun verb constituency': 82,\n",
       " 'noun verb constituency parsing': 146,\n",
       " 'verb constituency parsing build': 314,\n",
       " 'constituency parsing build parse': 42,\n",
       " 'parsing build parse tree': 170,\n",
       " 'build parse tree syntax': 28,\n",
       " 'parse tree syntax tree': 164,\n",
       " 'tree syntax tree rooted': 283,\n",
       " 'syntax tree rooted ordered': 258,\n",
       " 'tree rooted ordered representation': 280,\n",
       " 'rooted ordered representation syntactic': 208,\n",
       " 'ordered representation syntactic structure': 153,\n",
       " 'representation syntactic structure sentence': 200,\n",
       " 'syntactic structure sentence string': 248,\n",
       " 'structure sentence string word': 241,\n",
       " 'resulting': 201,\n",
       " 'underly': 296,\n",
       " 'function': 70,\n",
       " 'translator': 274,\n",
       " 'recognition': 192,\n",
       " 'resulting parse': 202,\n",
       " 'tree underly': 284,\n",
       " 'underly function': 297,\n",
       " 'function language': 71,\n",
       " 'language translator': 93,\n",
       " 'translator speech': 275,\n",
       " 'speech recognition': 229,\n",
       " 'resulting parse tree': 203,\n",
       " 'parse tree underly': 165,\n",
       " 'tree underly function': 285,\n",
       " 'underly function language': 298,\n",
       " 'function language translator': 72,\n",
       " 'language translator speech': 94,\n",
       " 'translator speech recognition': 276,\n",
       " 'resulting parse tree underly': 204,\n",
       " 'parse tree underly function': 166,\n",
       " 'tree underly function language': 286,\n",
       " 'underly function language translator': 299,\n",
       " 'function language translator speech': 73,\n",
       " 'language translator speech recognition': 95,\n",
       " 'ideally': 75,\n",
       " 'make': 122,\n",
       " 'either': 65,\n",
       " 'text': 266,\n",
       " 'understandable': 300,\n",
       " 'model': 135,\n",
       " 'people': 180,\n",
       " 'ideally analysis': 76,\n",
       " 'analysis make': 7,\n",
       " 'make output': 123,\n",
       " 'output either': 158,\n",
       " 'either text': 66,\n",
       " 'text speech': 267,\n",
       " 'speech understandable': 230,\n",
       " 'understandable nlp': 301,\n",
       " 'nlp model': 141,\n",
       " 'model people': 136,\n",
       " 'ideally analysis make': 77,\n",
       " 'analysis make output': 8,\n",
       " 'make output either': 124,\n",
       " 'output either text': 159,\n",
       " 'either text speech': 67,\n",
       " 'text speech understandable': 268,\n",
       " 'speech understandable nlp': 231,\n",
       " 'understandable nlp model': 302,\n",
       " 'nlp model people': 142,\n",
       " 'ideally analysis make output': 78,\n",
       " 'analysis make output either': 9,\n",
       " 'make output either text': 125,\n",
       " 'output either text speech': 160,\n",
       " 'either text speech understandable': 68,\n",
       " 'text speech understandable nlp': 269,\n",
       " 'speech understandable nlp model': 232,\n",
       " 'understandable nlp model people': 303}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv4.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 335)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3[0].shape # due to ngrams the feature are collected for unigram bigram and trigrams all in X3 due to ngrams_range = (1,4)\n",
    "#here, the feature is collected through the combinations of the two words, three words and four words form the corpus sequence wised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
